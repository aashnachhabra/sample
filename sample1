import os
import shutil
import json
import logging
import requests  # Import requests module
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
import openai
import fitz  # PyMuPDF for PDF text extraction
from pymongo import MongoClient
import markdown
# Load environment variables
load_dotenv()

# Initialize OpenAI Azure client
openai.api_type = "azure"
openai.api_base = os.getenv("AZURE_OPENAI_ENDPOINT")
openai.api_version = "2023-07-01-preview"
openai.api_key = os.getenv("AZURE_OPENAI_API_KEY")

# MongoDB Configuration
MONGO_URI = os.getenv("MONGO_URI")
DB_NAME = "planlibrary_api_db"
COLLECTION_NAME = "planlibrary_med_api"

# Connect to MongoDB
try:
    mongo_client = MongoClient(MONGO_URI, serverSelectionTimeoutMS=5000)
    db = mongo_client[DB_NAME]
    collection = db[COLLECTION_NAME]
    print("✅ Connected to MongoDB")
except Exception as e:
    print(f"❌ MongoDB Connection Error: {e}")

app = FastAPI()

# Enable CORS for frontend communication
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Change this in production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Storage for uploaded files
UPLOAD_DIR = "uploads"
os.makedirs(UPLOAD_DIR, exist_ok=True)
uploaded_texts = []  # Stores extracted text from uploaded PDFs & text files
uploaded_json_data = []  # Stores JSON data from uploaded files
fetched_json_data = []  # Stores JSON data from MongoDB

@app.post("/upload/")
async def upload_files(files: list[UploadFile] = File(...)):
    """Handles multiple file uploads (PDFs, text, JSON)."""
    global uploaded_texts, uploaded_json_data
    uploaded_texts.clear()
    uploaded_json_data.clear()
    for file in files:
        file_location = os.path.join(UPLOAD_DIR, file.filename)
        try:
            with open(file_location, "wb") as f:
                shutil.copyfileobj(file.file, f)
            # Process based on file type
            if file.filename.endswith(".pdf"):
                uploaded_texts.append(extract_text_from_pdf(file_location))
            elif file.filename.endswith(".json"):
                with open(file_location, "r", encoding="utf-8") as f:
                    json_data = json.load(f)
                    uploaded_json_data.append(json_data)
            else:
                with open(file_location, "r", encoding="utf-8") as f:
                    uploaded_texts.append(f.read())
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"File processing failed: {str(e)}")
    return {"message": "Files uploaded successfully", "uploaded_files": [file.filename for file in files]}

def extract_text_from_pdf(pdf_path):
    """Extracts text from a PDF file."""
    text = ""
    try:
        doc = fitz.open(pdf_path)
        for page in doc:
            text += page.get_text("text") + "\n"
        return text.strip()
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to extract text from PDF: {str(e)}")

@app.get("/fetch-json/")
async def fetch_json_from_mongo():
    """Fetches a limited number of JSON documents from MongoDB."""
    global fetched_json_data
    fetched_json_data.clear()
    try:
        fetched_json_data = list(collection.find({}, {"_id": 0}).limit(5))  # Fetch 5 JSON documents
        if not fetched_json_data:
            return {"message": "No JSON data found in MongoDB"}
        return {"message": "Fetched JSON data successfully", "json_data": fetched_json_data}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"MongoDB fetch error: {str(e)}")

@app.post("/chat/")
async def chat(user_query: dict):
    """Handles chat requests based on uploaded or fetched documents."""
    global uploaded_texts, uploaded_json_data, fetched_json_data
    # Determine available data source
    if not uploaded_texts and not uploaded_json_data and not fetched_json_data:
        raise HTTPException(status_code=400, detail="No documents uploaded or fetched. Please upload or fetch data first.")
    
    if uploaded_json_data:
        formatted_json = json.dumps(uploaded_json_data, indent=2)
        messages = [
            {"role": "system", "content": "You are an AI assistant that provides detailed information about health insurance plans based on JSON data."},
            {"role": "system", "content": f"Here is the JSON data for the plan details:\n\n{formatted_json}"},
            {"role": "user", "content": user_query["query"]},
        ]
    elif fetched_json_data:
        formatted_json = json.dumps(fetched_json_data, indent=2)
        messages = [
            {"role": "system", "content": "You are an AI assistant that provides detailed information about health insurance plans based on JSON data."},
            {"role": "system", "content": f"Here is the JSON data for the plan details:\n\n{formatted_json}"},
            {"role": "user", "content": user_query["query"]},
        ]
    else:
        combined_text = "\n\n".join(uploaded_texts)
        messages = [
            {"role": "system", "content": "You are an AI assistant that provides answers based on the provided documents."},
            {"role": "system", "content": f"Here are the uploaded documents:\n\n{combined_text}"},
            {"role": "user", "content": user_query["query"]},
        ]
    
    # Call OpenAI API
    try:
        response = openai.chat.completions.create(
            model="gpt-4-deployment",
            messages=messages,
            temperature=0.5
        )
        return {"response": response.choices[0].message.content}
        # llm_answer = response.choices[0].message.content

        # # Prepare the request body for the evaluation API
        # eval_request_body = {
        #     "question": user_query["query"],
        #     "groundAnswer": "Based on the provided document, the scheduled jobs involved in member enrollment via CMT and CIDM JSON files are: 1. EFPC 2. EFC 3. EFMGC These jobs are mentioned in the context of verifying if any of them get stuck in a running or cancelled state, which could lead to files being stuck in the 'Processing' status. If such an issue occurs, the document suggests checking these scheduled jobs from the scheduled job screen. If found in a running or cancelled state, they should be updated to an idle state and then processed to move the files from 'Processing' to 'Completed' status.",
        #     "llmAnswer": llm_answer,
        #      "retrievalContext": [
        #         "The scheduled jobs involved in member enrollment via CMT and CIDM JSON files are: 1. EFPC 2. EFC 3. EFMGC.",
        #         "These jobs are mentioned in the context of verifying if any of them get stuck in a running or cancelled state, which could lead to files being stuck in the 'Processing' status.",
        #         "If such an issue occurs, the document suggests checking these scheduled jobs from the scheduled job screen.",
        #         "If found in a running or cancelled state, they should be updated to an idle state and then processed to move the files from 'Processing' to 'Completed' status."
        #     ],
        #     "contextualPrecision": True,
        #     "contextualRecall": True,
        #     "faithfulness": True,
        #     "answerRelevancy": True,
        #     "gEval": True
        # }

        # # Make the POST request to the evaluation API
        # eval_response = requests.post("http://localhost:8080/deepeval/evaluate_metrics", json=eval_request_body)
        # eval_response_data = eval_response.json()
        # formatted_response = response.choices[0].message.content
        # # Convert Markdown to HTML
        # html_response = markdown.markdown(formatted_response)
        # return {"response": html_response, "evaluation": eval_response_data}
    except Exception as e:
        logging.error(f"Chat API error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Chat API error: {str(e)}")

I have made this poc project which i need to demo and explain in a ai learning session. I need to give a brief about the usecase, demo it and also explain bit of the codebase.
Note: there are gonna be beginners in this meeting so i want you to help me  create a script for this meeting and how i should go about it. Script should be absolutely beginner friendly
I need to also give a very brief info of the tech stack i used which is fast api and react and tailwind css for frontend.
To give a little insight about this project i have provided my main.py file. This project basically trains the llm model based on the pdf/pdfs or json/jsons upload. It can also directly fetch json from mongodb
Please help me create content for this meeting and how i should present it in simple easy language and it should not seem scripted or ai generated at all.


