import fitz import re import logging import concurrent.futures import orjson from google import genai from google.genai import types from config import (PROJECT_ID, LOCATION, GEMINI_MODEL ) logging.basicConfig( level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s' ) logger = logging.getLogger(__name__) def fix_malformed_json(json_string): try: json_string = re.sub(r'\\(?!["\\/bfnrtu])', '', json_string) json_string = json_string.replace('\\\\', '\\') json_string = re.sub(r'\\n', ' ', json_string) json_string = re.sub(r'\\t', ' ', json_string) json_string = re.sub(r'}\s*{', r'},{', json_string) json_string = json_string.strip() if not json_string.startswith("{") and not json_string.startswith("["): json_string = "{" + json_string if not json_string.endswith("}") and not json_string.endswith("]"): json_string = json_string + "}" try: orjson.loads(json_string) except orjson.JSONDecodeError as e: logger.warning(f"JSON still malformed after initial fixes: {e}. Attempting further corrections.") return json_string # to return the string, not a tuple return json_string except Exception as e: logger.error(f"Error fixing malformed JSON: {e}") return "{}" def split_pdf_by_pages_in_memory(pdf_path, pages_per_chunk=2): try: doc = fitz.open(pdf_path) split_chunks = [] for i in range(0, len(doc), pages_per_chunk): chunk_doc = fitz.open() for page_num in range(i, min(i + pages_per_chunk, len(doc))): chunk_doc.insert_pdf(doc, from_page=page_num, to_page=page_num) # Save chunk to bytes in memory chunk_bytes = chunk_doc.write() if chunk_bytes: # Only add non-empty chunks split_chunks.append(chunk_bytes) return split_chunks except Exception as e: logger.error(f"Error chunking DBS pdf: {e}") return [] def clean_escape_characters(data): if isinstance(data, dict): return {key.replace("\\n", " ").replace("\\t", " ").replace("\\", " "): clean_escape_characters(value) for key, value in data.items()} elif isinstance(data, list): return [clean_escape_characters(item) for item in data] elif isinstance(data, str): return data.replace("\\n", " ").replace("\\t", " ").replace("\\", " ") return data def merge_chunks_in_order(aggregated_results): try: sorted_chunks = sorted( [(key, value) for key, value in aggregated_results.items() if value], key=lambda x: int(x[0].split()[1]) ) final_json = {key: value for key, value in sorted_chunks} return final_json except Exception as e: logger.error(f"Error merging chunks in order: {e}") return None def process_chunk(idx, chunk_bytes, prompt): chunk_key = f"chunk {idx + 1}" logger.info(f"Processing {chunk_key}") if not chunk_bytes: logger.error(f"No data extracted for {chunk_key}. Skipping.") return chunk_key, None json_output = process_pdf_with_gemini(chunk_bytes, prompt) try: parsed_json = orjson.loads(json_output) return chunk_key, parsed_json except orjson.JSONDecodeError as e: logger.error(f"Failed to parse JSON for {chunk_key}: {e}") logger.debug(f"Raw JSON output for {chunk_key}: {json_output}") try: fixed_json_output = fix_malformed_json(json_output) parsed_json = orjson.loads(fixed_json_output) return chunk_key, parsed_json except Exception as fix_error: logger.error(f"Failed to fix JSON for {chunk_key}: {fix_error}") logger.debug(f"Raw JSON output for {chunk_key}: {json_output}") return chunk_key, None def process_pdf_with_gemini(chunk_bytes, prompt): try: client = genai.Client( vertexai=True, project=PROJECT_ID, location=LOCATION, ) responses = client.models.generate_content( model=GEMINI_MODEL, contents=[ types.Part.from_bytes( data=chunk_bytes, mime_type='application/pdf', ), prompt ] ) cleaned_responses = [] for response in responses: # Extract candidates from a tuple response candidates = None if isinstance(response, tuple) and response[0] == 'candidates': candidates = response[1] else: candidates = [response] # Loop through candidates and extract JSON from the text part for candidate in candidates: if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'): for part in candidate.content.parts: if hasattr(part, 'text') and part.text.strip().startswith("```json"): raw_text = part.text # Clean up code block markers and whitespace cleaned_response = raw_text.strip().strip("```json").strip("```").strip() cleaned_response = re.sub(r"^[^\{]+", "", cleaned_response) cleaned_responses.append(cleaned_response) else: continue output = "".join(cleaned_responses) sanitized_output = output.replace("\\", "\\\\") try: orjson.loads(sanitized_output) except orjson.JSONDecodeError: logger.warning("Sanitized JSON is invalid. Attempting to fix.") sanitized_output = fix_malformed_json(sanitized_output) return sanitized_output except Exception as e: logger.error(f"Error processing DBS pdf chunk with Gemini model: {e}") return None def remove_empty_keys(data): """ Recursively remove keys with value None from a dictionary. """ if isinstance(data, dict): return {k: remove_empty_keys(v) for k, v in data.items() if v is not None} elif isinstance(data, list): return [remove_empty_keys(item) for item in data] else: return data def process_pdf_to_json(file_path, output_file_path): prompt = f""" Role: You are an expert data extraction system specializing in parsing complex health insurance documents. Your task is to analyze the provided PDF and extract its information into a single, valid JSON object, strictly following the rules below. 1. **Top-Level Field Extraction** Before processing the main tables, you must first scan the entire document (especially the header section) to identify and extract the following top-level fields. These fields should be placed at the root level of the final JSON object. A. State: Task: Identify and extract the full name of the U.S. state explicitly mentioned in the document. Examples: "California", "Iowa", "Massachusetts" B. Medical Plan Code: Task: Detect and extract the primary medical plan code. This is often a short, capitalized alphanumeric pattern found near the plan name or in the document header/footer. Examples: "DNU3", "CZZL" C. RX Plan Code: Task: Locate and extract the prescription (RX) plan code. This alphanumeric pattern is typically found adjacent to or near the medicalPlanCode. Examples: "5U", "X01T" 2. **Required Output Format** Output should be a single valid JSON object with the following structure: {{ "State": "Full state name", "Medical Plan Code": "Medical plan code", "RX Plan Code": "RX plan code", "Section header from the document":{{ "Service label from the document":{{ "Column header": "value", "limitations": "text describing limitations, if present" }} }} }} 3. **Core Extraction Principles (Apply to ALL Tables)** A. Preserve Column Integrity (CRITICAL): Tables may have empty cells. When you encounter a visually empty cell, you must represent its value as `null` or omit the key. Do not shift data from subsequent columns to the left. The visual alignment of the columns is the ground truth. B. Handle Nested/Hierarchical Rows: Some tables use rows as sub-headers (e.g., "Physician's Office Visit" followed by indented rows for "Primary Care" and "Specialist"). You must capture this relationship by nesting the child rows within the parent row's JSON object. C. Capture Multi-line Rows: A single row's data might span multiple lines within a cell. Combine this multi-line text into a single string for that cell's value. D. Do Not Add Keys for Missing Columns: If a table is defined with only two columns (e.g., "Network" and "Out-of-Network"), do not invent and add a `Designated Network` key to the output for that table. 4. **Understanding and Extracting Document Structures** The input PDF document contains information in the following structures. Use these descriptions to guide your extraction logic. A. Table for "Annual Medical Deductible" Context: These tables have row labels like "Individual," "Family," "Single Coverage," etc., and column headers like "In-network," "Out-of-Network,". Extraction Rules: 1. Apply the Core Extraction Principles, especially Preserve Column Integrity. 2. If the table has only a single column for cost (e.g., "In-Network and Out-of-Network"), split it into two separate columns and apply that value to both the `In-network` and `Out-of-Network` keys in the final JSON. 3. IF: A service row provides only a single, non-network-specific value (e.g., "No.", "Not covered"). THEN: You must duplicate this exact value for both the In-network and Out-of-Network keys in the JSON output, preserving the original text and formatting. Example Output: {{ "In-network": "No.", "Out-of-Network": "No." }} B. Table for "Annual Out-of-Pocket Limit" Context: These tables have row labels like "Individual," "Family," "Single Coverage," etc., and column headers like "In-network," "Out-of-Network,". Extraction Rules: 1. Apply the Core Extraction Principles, especially Preserve Column Integrity. 2. If the table has only a single column for cost (e.g., "In-Network and Out-of-Network"), split it into two separate columns and apply that value to both the `In-network` and `Out-of-Network` keys in the final JSON. 3. IF: A service row provides only a single, non-network-specific value (e.g., "No.", "Not covered"). THEN: You must duplicate this exact value for both the In-network and Out-of-Network keys in the JSON output, preserving the original text and formatting. Example Output: {{ "In-network": "No.", "Out-of-Network": "No." }} C. Table for "Medical Benefits" Context: This is the main table, often under a header like "Copays ($) and Coinsurance (%) for Covered Health Care Services." It has section headers ("Inpatient Care," "Outpatient Care"), row labels for services ("Specialist," "Urgent Care"), and sometimes descriptive text beneath a row label. Extraction Rules: 1. Top-Level Structure: - Use the section headers (e.g., "Outpatient Care") as top-level keys in your JSON output. - Use the service row labels (e.g., "Home Health Care") as nested keys. - If you find descriptive text directly beneath a service row, treat it as a limitations key for that service. 2. Critical Column Handling Logic: Your primary task is to identify the number of network columns present for a given service and apply the corresponding rule below. Rule Set 1: For 3-Column Tables (Designated Network, Network, Out-of-Network) Apply the following sub-rules in this specific order of priority: A. The "Empty Designated Network" Exception: IF a row has a Designated Network column, and the cell for that row is visually empty, THEN you must set the value of Designated Network key to "null" for your JSON output. B. The General "Empty Cell" Rule: IF any other cell (e.g., in the Network or Out-of-Network columns) is visually empty, THEN you must represent its value as "null" in the JSON output. Comprehensive 3-Column Example: Given this table structure / markdown: | Service | Designated Network | Network | Out-of-Network | |-----------------------------------------------------------------------------|--------------------|----------|----------------| | Home Health Care | | 20%* | No copay | |-----------------------------------------------------------------------------|--------------------|----------|----------------| | Lab, X-Ray and Diagnostic - Outpatient - Lab Testing | 20%* | 50%* | Not covered | |-----------------------------------------------------------------------------|--------------------|----------|----------------| | Lab, X-Ray and Diagnostic - Outpatient - X-Ray and other Diagnostic Testing | | No copay | | Correct JSON Output: "Home Health Care": {{ "Designated Network": "20%*", "Network": "20%*", "Out-of-Network": "No copay", "limitations": "Additional descriptive text if present." }}, "Lab, X-Ray and Diagnostic - Outpatient - Lab Testing": {{ "Designated Network": "20%*", "Network": "50%*", "Out-of-Network": "Not covered", "limitations": "Additional descriptive text if present." }}, "Lab, X-Ray and Diagnostic - Outpatient - X-Ray and other Diagnostic Testing": {{ "Designated Network": "No copay", "Network": "No copay", "Out-of-Network": null, "limitations": "Additional descriptive text if present." }} Rule Set 2: For 2-Column Tables Case A: Network, Out-of-Network are present Rule: Assign the Network value to both the Designated Network and Network keys. Assign the Out-of-Network value to its key. Example table structure / markdown: | Service | Network | Out-of-Network | |--------------|---------|----------------| | Service Name | $25* | 50%* | Correct JSON Output: "Service Name": {{ "Designated Network": "$25*", "Network": "$25*", "Out-of-Network": "50%*", "limitations": "Additional descriptive text if present." }} Case B: Designated Network, Network are present Rule: Map Designated Network and Network to their keys. Set the Out-of-Network key to null. Example table structure / markdown: | Service | Designated Network | Network | |--------------|--------------------|---------| | Service Name | $10* | $20* | Correct JSON Output: "Service Name": {{ "Designated Network": "$10*", "Network": "$20*", "Out-of-Network": null, "limitations": "Additional descriptive text if present." }} Rule Set 3: For 1-Column Tables Case: Network only is present Rule: Assign the Network value only to the Network key. Set both Designated Network and Out-of-Network keys to null. Example table structure / markdown: | Service | Network | |--------------|---------| | Service Name | $30* | Output: "Service Name": {{ "Designated Network": null, "Network": "$30*", "Out-of-Network": null, "limitations": "Additional descriptive text if present." }} 3. Crucial Instructions for High-Accuracy Extraction: 1. Identify the Target Row: First, locate the exact row corresponding to the "Target Benefit" key: "X-Ray and other Diagnostic Testing¹". This row is a sub-item under "Lab, X-Ray and Diagnostic - Outpatient". 2. Anchor to Column Headers: For this specific row, you must perform a separate lookup for each column header: "Designated Network", "Network", and "Out-of-Network". 3. Enforce Strict Vertical Alignment: This is the most important rule. For each column header, extract the text value that is located directly and vertically below that header within the target row. Do not let your focus drift horizontally to adjacent columns. The visual grid of the table is your ground truth. Example Thought Process (for "Lab, X-Ray and Diagnostic - Outpatient - X-Ray and other Diagnostic Testing" row): Goal: Extract data for the "Lab, X-Ray and Diagnostic - Outpatient - X-Ray and other Diagnostic Testing" row. Step 1: Find the "Lab, X-Ray and Diagnostic - Outpatient - X-Ray and other Diagnostic Testing" row. Step 2: Look under the "Designated Network" column header for this row. The value is "No copay". Step 3: Look under the "Network" column header for this row. The value is "No copay". Step 4: Look under the "Out-of-Network" column header for this row. The value is "50%". Result: The values are correctly and independently mapped from their specific column. Extract Limitations: Find the footnote marker (the superscript ¹) associated with the benefit. Locate the corresponding footnote at the bottom of the page and extract its full text for the "limitations" field. D. Table for "Annual Pharmacy Deductible" Context: These tables have row labels like "Individual" and "Family" and column headers like "In-network," "Out-of-Network," and sometimes "In Network and Out-of-Network." Extraction Rules: 1. Apply the Core Extraction Principles, especially Preserve Column Integrity. 2. If the table has only a single column for cost (e.g., "In-Network and Out-of-Network"), split it into two separate columns and apply that value to both the `In-network` and `Out-of-Network` keys in the final JSON. 3. In-network: Map the value from the "In-network" column directly to the In-network key. 4. Out-of-Network: Map the value from the "Out-of-Network" column to the Out-of-Network key. If this column is present but the cell is visually empty, set the value to null. 5. limitations: If descriptive text is found directly beneath a service row, map this text to the limitations key. 6. IF: A service row provides only a single, non-network-specific value (e.g., "No.", "Not covered"). THEN: You must duplicate this exact value for both the In-network and Out-of-Network keys in the JSON output, preserving the original text and formatting. Example Output: {{ "In-network": "No.", "Out-of-Network": "No." }} E. Table for "Prescription Drugs" Context: This table is often under a header like "Prescription Drugs." It has section headers for Tiers ("Tier 1," "Tier 2") and columns for different pharmacy types. Extraction Rules: 1. Apply all Core Extraction Principles. 2. Use the Tier headers as the primary keys for this section. 3. Map the tiers and their costs under the appropriate network. 4. Do not extract "Up to a 31-day supply" and "Up to a 90-day supply" as separate services. F. Table for "Specialty Prescription Drugs" Context: This table is often under a header like "Specialty Prescription Drugs." It has section headers for Tiers ("Tier 1," "Tier 2") and columns for different pharmacy types. Extraction Rules: 1. Apply all Core Extraction Principles. 2. Use the Tier headers as the primary keys for this section. 3. Map the tiers and their costs under the appropriate network. G. Unstructured Text for "Medical Exclusions" Context: This section is typically a bulleted or numbered list of services that are not covered. Extraction Rule: Extract the content of this section as an array of strings under a single key, `"Medical Exclusions"`. Each item in the list should be a separate string in the array. 5. **Specific Data Handling Scenarios** After identifying the text in a cell, apply these conditional logic rules before finalizing the JSON for a row. A. Scenario 1: The "Based on Where" Rule IF: A cell's value is "The amount you pay is based on where the covered health care service is provided.": THEN: Copy this exact text as the value for all available network keys (Designated Network, Network, Out-of-Network) for that specific service row. Example Output: {{ "Designated Network": "The amount you pay is based on where the covered health care service is provided.", "Network": "The amount you pay is based on where the covered health care service is provided.", "Out-of-Network": "The amount you pay is based on where the covered health care service is provided.", "limitations": "Additional descriptive text if present." }} B. Scenario 2: The "Split Costshare" Rule IF: A cell's value contains two distinct parts, like "You pay a $500 per occurrence deductible per service prior to and in addition to paying any Annual Deductible and any coinsurance amount. 20%*": THEN: You must split the value and create new keys: 1. Identify the descriptive part (e.g., "You pay a $500 per occurrence deductible per service prior to and in addition to paying any Annual Deductible and any coinsurance amount."). 2. Identify the final cost part (e.g., "20%*"). 3. Assign the descriptive part to new keys: Costshare DN, Costshare IN, and Costshare OON. 4. Assign the final cost part to the original network keys: Designated Network, Network, and Out-of-Network. Example Output: {{ "Costshare DN": "You pay a $500 per occurrence deductible per service prior to and in addition to paying any Annual Deductible and any coinsurance amount.", "Costshare IN": "You pay a $500 per occurrence deductible per service prior to and in addition to paying any Annual Deductible and any coinsurance amount.", "Costshare OON": "You pay a $500 per occurrence deductible per service prior to and in addition to paying any Annual Deductible and any coinsurance amount.", "Designated Network": "20%*", "Network": "20%*", "Out-of-Network": "20%*", "limitations": "Additional descriptive text if present." }} 6. **Service-Specific Instructions** Apply the following instructions to each service as it is identified. 1. Primary Care Provider / Primary Care Physician For the sub-row labeled "Covered persons less than age 19": - Extract only the value from the "Network" column. - Disregard all other columns for this specific sub-row. Example: Given Network: "No copay", Out-of-Network: "50%" "Covered persons less than age 19": {{ "Network": "No copay" }} 2. Specialist, Urgent Care Center Services, Virtual Care Services Apply parent key as "Office Services - Sickness & Injury" for this service. 3. Hospice Care Apply parent key as "Other Services" for this service. 4. Virtual Care Services Apply the "Empty Cell" Rule if the Designated Network cell is empty. 5. Lab, X-Ray and Diagnostic - Outpatient - Lab Testing Apply the "Empty Cell" Rule if the Designated Network cell is empty. 6. Lab, X-Ray and Diagnostic - Outpatient - X-Ray and other Diagnostic Testing Apply the "Empty Cell" Rule if the Designated Network cell is empty. 7. Major Diagnostic and Imaging - Outpatient Apply the "Empty Cell" Rule if the Designated Network cell is empty. 8. Rehabilitation Services / Habilitative Services - Outpatient Apply Nested Sub-Row Extraction for sub-rows like "Manipulative Treatment" and "Other rehabilitation services". 9. Surgery - Outpatient - Apply Nested Sub-Row Extraction for sub-rows like "For services provided at an ambulatory surgical center or in a physician’s office" and "For services provided at an outpatient hospital-based surgical center". - Within each extracted sub-row object, apply Network Column Logic to correctly map the network costs. Example Structure: Surgery - Outpatient: {{ "For services provided at an ambulatory surgical center or in a physician’s office": {{ "Designated Network": "Value for Designated Network", "Network": "Value for Network", "Out-of-Network": "Value for Out-of-Network", "limitations": "Text describing limitations, if present" }} "For services provided at an outpatient hospital-based surgical center": {{ "Designated Network": "Value for Designated Network", "Network": "Value for Network", "Out-of-Network": "Value for Out-of-Network", "limitations": "Text describing limitations, if present" }} }} 10. Eyeglass Lenses Apply the "Empty Cell" Rule if the Designated Network cell is empty. By following these combined instructions, you will correctly interpret the varied layouts and produce a clean, structured, and accurate JSON output. """ split_chunks = split_pdf_by_pages_in_memory(file_path, pages_per_chunk=2) logger.info(f"Split PDF into {len(split_chunks)} in-memory chunks.") aggregated_results = {} with concurrent.futures.ThreadPoolExecutor() as executor: future_to_chunk = { executor.submit(process_chunk, idx, chunk_bytes, prompt): idx for idx, chunk_bytes in enumerate(split_chunks) } for future in concurrent.futures.as_completed(future_to_chunk): chunk_key, result = future.result() if result is not None: aggregated_results[chunk_key] = result cleaned_results = clean_escape_characters(aggregated_results) cleaned_json = remove_empty_keys(cleaned_results) final_json = merge_chunks_in_order(cleaned_json) with open(output_file_path, "wb") as json_file: json_file.write(orjson.dumps(final_json, option=orjson.OPT_INDENT_2)) logger.info(f"Final JSON saved in ascending order to: {output_file_path}") return final_json
